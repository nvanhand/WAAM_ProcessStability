{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d77741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib import ticker as ticker\n",
    "import time\n",
    "from typing import List, Tuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd6404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "import joblib\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7323f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(scores):\n",
    "        # Calculate MSE, RMSE, R2 values\n",
    "    Best_CV_MSE = min(abs(scores['test_neg_mean_squared_error']))\n",
    "    Best_CV_RMSE = np.sqrt(Best_CV_MSE)\n",
    "    Best_CV_R2 = max(scores['test_r2'])\n",
    "    Worst_CV_MSE = max(abs(scores['test_neg_mean_squared_error']))\n",
    "    Worst_CV_RMSE = np.sqrt(Worst_CV_MSE)\n",
    "    Worst_CV_R2 = min(scores['test_r2'])\n",
    "    Ave_CV_MSE = np.average(abs(scores['test_neg_mean_squared_error']))\n",
    "    Ave_CV_RMSE = np.sqrt(Ave_CV_MSE)\n",
    "    Ave_CV_R2 = np.average(scores['test_r2'])\n",
    "\n",
    "    # Print out cross validation history data\n",
    "    print(\"~~~~ Cross Validation Results ~~~~\")\n",
    "    print(\"Best MSE CV: \", Best_CV_MSE)\n",
    "    print(\"Best RMSE CV: \", Best_CV_RMSE)\n",
    "    print(\"Best R2 CV: \", Best_CV_R2)\n",
    "    print(\"Worst MSE CV: \", Worst_CV_MSE)\n",
    "    print(\"Worst RMSE CV: \", Worst_CV_RMSE)\n",
    "    print(\"Worst R2 CV: \", Worst_CV_R2)\n",
    "    print('Average MSE CV: ', Ave_CV_MSE)\n",
    "    print('Average RMSE CV: ', Ave_CV_RMSE)\n",
    "    print(\"Average R2 CV: \", Ave_CV_R2)\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "\n",
    "def ANN_Train(X, y, test_size, train_size, k, epochs, hidden_nodes, hidden_layers, batch_size, learning_rate):\n",
    "    hidden_layer_sizes = tuple(np.full(hidden_layers, hidden_nodes))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, train_size=train_size, random_state=42)\n",
    "    model = Pipeline([('scaler', StandardScaler(with_mean=True)), ('ANN', MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, activation='relu', solver='adam', \n",
    "                                                                                       batch_size=batch_size, max_iter=epochs, learning_rate_init=learning_rate))])\n",
    "\n",
    "    print(\"Cross validating...\")\n",
    "    scores = cross_validate(model, X_train, y_train, cv=k, scoring=('r2', 'neg_mean_squared_error'), return_train_score=True)\n",
    "    \n",
    "    print_scores(scores)\n",
    "\n",
    "    print(\"Fitting model...\")\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Output cross validation data\n",
    "    CrossValData = [Best_CV_MSE, Best_CV_RMSE, Best_CV_R2, Worst_CV_MSE, Worst_CV_RMSE, Worst_CV_R2, Ave_CV_MSE, Ave_CV_RMSE, Ave_CV_R2]\n",
    "\n",
    "    return model, X_test, y_test, CrossValData\n",
    "\n",
    "def ANN_Test(model, X_test, y_test, DataEfficiencyToggle):\n",
    "\n",
    "    print(\"Testing model...\")\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate R2, RMSE, and MSE metrics for test data\n",
    "    SparseDataTest_R2 = r2_score(y_test, y_pred)\n",
    "    SparseDataTest_MSE = mean_squared_error(y_test, y_pred, squared=True)\n",
    "    SparseDataTest_RMSE = np.sqrt(SparseDataTest_MSE)\n",
    "\n",
    "    # Print model info after CV\n",
    "    print(\"~~~~~~~~~ Final Model Structure Info ~~~~~~~~~\")\n",
    "    print(\"Number of Layers: \", model[1].n_layers_)\n",
    "    print(\"Number of input features: \", model[1].n_features_in_)\n",
    "    print(\"Number of outputs: \", model[1].n_outputs_)\n",
    "    print(\"Number of iterations ran: \", model[1].n_iter_)\n",
    "    print(\"~~~~~~~~~ Final Model Error Info ~~~~~~~~~\")\n",
    "    print(\"Test MSE: \", Test_MSE)\n",
    "    print(\"Test RMSE: \", Test_RMSE)\n",
    "    print(\"Test R2: \", Test_R2)\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "\n",
    "    # Plot ANN results.\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.suptitle(\"ANN Results\")\n",
    "\n",
    "    ax[0].plot(np.linspace(1, len(model[1].loss_curve_), len(model[1].loss_curve_)), model[1].loss_curve_)\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Loss (Mean Squared Error)\")\n",
    "    ax[0].set_title('Epoch History, MSE: {:.2f}, RMSE: {:.2f}, R2: {:.2f}'.format(Test_MSE, Test_RMSE, Test_R2), fontsize=7)\n",
    "\n",
    "    # Parity Plot\n",
    "    ax[1].plot(y_test, y_pred, 'r*')\n",
    "    ax[1].set_xlabel(\"y_test\")\n",
    "    ax[1].set_ylabel(\"y_pred\")\n",
    "    ax[1].set_title('Parity Plot, MSE: {:.2f}, RMSE: {:.2f}, R2: {:.2f}'.format(Test_MSE, Test_RMSE, Test_R2), fontsize=7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return SparseDataTest_R2, SparseDataTest_RMSE, SparseDataTest_MSE,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd3a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Import dataset\n",
    "\n",
    "\n",
    "# Define ANN model hidden layer structure and training parameters\n",
    "hidden_layers = 3\n",
    "hidden_nodes = 8\n",
    "test_size = 0.2\n",
    "train_size = 0.8\n",
    "k = 5\n",
    "batch_size = 100\n",
    "epochs = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Preprocess and parse data.\n",
    "# For non-data efficiency modeling, set desired statistical features and set DataEfficiencyToggle = 0\n",
    "# For data efficiency modeling, set number of packets, layer numbers, and set DataEfficiencyToggle = 1\n",
    "\n",
    "DataEfficiencyToggle = 1\n",
    "\n",
    "if DataEfficiencyToggle == 0:\n",
    "    StatisticalFeatures = ['StDev', 'Skew', 'Kurtosis']\n",
    "\n",
    "    # Parse dataset\n",
    "\n",
    "if DataEfficiencyToggle == 1:\n",
    "    PacketNumber = # any integer value between 1 and 10\n",
    "    LayerNumbers = # any integer value between 1 and 20\n",
    "\n",
    "    # Packetize data\n",
    "\n",
    "    # Iterate through data stream types (ie current, CTWD, etc.)\n",
    "\n",
    "    # Define input and output variables (X and y)\n",
    "\n",
    "    # Train ANN\n",
    "    model, X_test, y_test, CrossValData = ANN_Train(X, y, test_size, train_size, k, epochs, hidden_nodes, hidden_layers, batch_size, learning_rate)\n",
    "\n",
    "    # Test ANN\n",
    "    SparseDataTest_R2, SparseDataTest_RMSE, SparseDataTest_MSE = ANN_Test(model, X_test, y_test, DataEfficiencyToggle)\n",
    "\n",
    "# Show plots\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
